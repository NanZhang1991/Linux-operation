{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('我的喉咙发炎了要买点阿莫西林吃', [['细林', '西林', 12, 14]])\n"
     ]
    }
   ],
   "source": [
    "import pycorrector\n",
    "error_sentence_1 = '我的喉咙发炎了要买点阿莫细林吃'\n",
    "pycorrector.enable_char_error(enable=False)\n",
    "correct_sent = pycorrector.correct(error_sentence_1)\n",
    "print(correct_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('我地喉咙 发炎 了 要 买点 阿莫西林 吃', [['细林', '西林', 17, 19]])\n"
     ]
    }
   ],
   "source": [
    "correct_sent = pycorrector.correct('我 喉咙 发炎 了 要 买点 阿莫细林 吃')\n",
    "print(correct_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[  DEBUG 20201103 09:55:06 detector:  87] Loaded language model: D:/My_Document/vscode/practice/NLP/zh_giga.no_cna_cmn.prune01244.klm, spend: 31.204 s.\n",
      "[  DEBUG 20201103 09:55:09 detector: 106] Loaded dict file, spend: 2.977 s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "少先队员应该为老人让座 [['因该', '应该', 4, 6], ['坐', '座', 10, 11]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pycorrector import Corrector\n",
    "\n",
    "lm_path = os.path.join('D:/My_Document/vscode/practice/NLP/zh_giga.no_cna_cmn.prune01244.klm')\n",
    "model = Corrector(language_model_path=lm_path)\n",
    "\n",
    "corrected_sent, detail = model.correct('少先队员因该为老人让坐')\n",
    "print(corrected_sent, detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我咳搜了 []\n"
     ]
    }
   ],
   "source": [
    "corrected_sent, detail = model.correct('我咳搜了')\n",
    "print(corrected_sent, detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('我的喉咙发炎了要买点阿莫西林吃', [['细林', '西林', 12, 14]])\n"
     ]
    }
   ],
   "source": [
    "error_sentence_3 = '我的喉咙发炎了要买点阿莫细林吃'\n",
    "pycorrector.enable_char_error(enable=True)\n",
    "correct_sent = pycorrector.correct(error_sentence_3)\n",
    "print(correct_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､\\u3000、〃〈〉《》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏﹑﹔·！？｡。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zhon import hanzi\n",
    "hanzi.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_sentence_3 ='标点符号使用错误了,不是吗?'\n",
    "error_sentence_3.replace(',','，')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_errors = pycorrector.detect('少先队员因该为老人让坐')\n",
    "print(idx_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pycorrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corrector',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'config',\n",
       " 'correct',\n",
       " 'corrector',\n",
       " 'detect',\n",
       " 'detector',\n",
       " 'en_correct',\n",
       " 'en_spell',\n",
       " 'enable_char_error',\n",
       " 'enable_word_error',\n",
       " 'get_homophones_by_char',\n",
       " 'get_homophones_by_pinyin',\n",
       " 'get_same_pinyin',\n",
       " 'get_same_stroke',\n",
       " 'language_model_path',\n",
       " 'ngram_score',\n",
       " 'ppl_score',\n",
       " 'set_custom_confusion_dict',\n",
       " 'set_custom_word',\n",
       " 'set_language_model_path',\n",
       " 'set_log_level',\n",
       " 'simplified2traditional',\n",
       " 'traditional2simplified',\n",
       " 'utils',\n",
       " 'word_frequency']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pycorrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, fitz\n",
    "fname = 'D:/My_Document/vscode/practice/NLP/2019年第一期都江堰兴堰投资有限公司停车场专项债券募集说明书.pdf'  # get document filename\n",
    "doc = fitz.open(fname)  # open document\n",
    "out = open(fname + \".txt\", \"wb\")  # open text output\n",
    "for page in doc:  # iterate the document pages\n",
    "    text = page.getText().encode(\"utf8\")  # get plain text (is in UTF-8)\n",
    "    out.write(text)  # write text of page\n",
    "    out.write(bytes((12,)))  # write page delimiter (form feed 0x0C)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, fitz\n",
    "fname = 'D:/My_Document/vscode/practice/NLP/2019年第一期都江堰兴堰投资有限公司停车场专项债券募集说明书.pdf'  # get document filename\n",
    "doc = fitz.open(fname)  # open document\n",
    "out = open(fname + \".txt\", \"wb\")  # open text output\n",
    "doc_text = {}\n",
    "for page, doc in enumerate(doc):  # iterate the document pages\n",
    "    doc_text[page]= doc.getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'都江堰兴堰投资有限公司                          “19 兴堰专项债 01”募集说明书 \\n \\n3 \\n公开发行和通过上海证券交易所向机构投资者（国家法律、法规禁止购买\\n者除外）协议发行。 \\n债券形式及托管方式：实名制记账式债券，投资者通过协议方式认购\\n在上海证券交易所发行的债券由中国证券登记公司上海分公司登记托管；\\n在承销团成员设置的营业网点认购的债券由中央国债登记公司登记托管。 \\n债券担保：本期债券由天府(四川)信用增进股份有限公司提供全额无\\n条件不可撤销连带责任保证担保。 \\n信用级别：经东方金诚综合评定，本期债券的信用级别为AAA级，评\\n级展望为稳定，发行人的主体长期信用等级为AA级。 \\n资金监管人/债权代理人：发行人聘请成都银行股份有限公司都江堰支\\n行作为本期债券的资金监管人和债权代理人。发行人与成都银行股份有限\\n公司都江堰支行签署了《账户及资金监管协议》和《债权代理协议》，成\\n都银行股份有限公司都江堰支行将代理债券投资人监督发行人经营状况、\\n募集资金使用情况。同时，如发行人未按募集说明书的规定履行其在本期\\n债券项下的还本付息义务，成都银行股份有限公司都江堰支行将协助或代\\n理投资者向发行人追偿。 \\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_text[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cn_cut_sentence(text):\n",
    "    sentence_list = re.split(r'(\\.|\\!|\\?|。|！|？|\\.{6})', text)\n",
    "    return sentence_list\n",
    "\n",
    "def cn_tokenize(sentence):\n",
    "    seg_list = jieba.cut(sentence)\n",
    "    return \",\".join(seg_list).split(\",\")\n",
    "\n",
    "import jieba\n",
    "import re \n",
    "import string\n",
    "from zhon import hanzi\n",
    "def cn_text_process(text_sent):   \n",
    "    #对文章进行分句\n",
    "    text_sent = re.sub('\\n','',text_sent)\n",
    "    new_text_sent =\"\"\n",
    "    sentence_list = cn_cut_sentence(text_sent)\n",
    "    for sent in sentence_list:\n",
    "        word_list = cn_tokenize(sent)\n",
    "#         seg_words = cn_del_stopwords(word_list)  \n",
    "        seg_words = word_list\n",
    "        ren_words = remove_numbers(seg_words)\n",
    "        rep_words = remove_punctuation(ren_words) \n",
    "        new_words = \" \".join(rep_words)        \n",
    "        new_text_sent += new_words + \"，\"       \n",
    "    return new_text_sent\n",
    "\n",
    "#去除文本中的数字 (主要针对分词后的英文，分词后的中文不存在)\n",
    "def remove_numbers(words_list): \n",
    "    renum_words = [word for word in words_list if not word.isnumeric()]\n",
    "    new_words = [word for word in renum_words if not re.findall('-\\d+',word)]\n",
    "    return new_words\n",
    "\n",
    "#去除中英文标点符号\n",
    "def remove_punctuation(words_list):\n",
    "    new_words = [word for word in words_list if word not in (set(hanzi.punctuation)|set(string.punctuation))]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  债券 形式 及 托管 方式 实名制 记账式 债券 投资者 通过 协议 方式 认购 在 上海证券交易所 发行 的 债券 由 中国 证券 登记 公司 上海 分公司 登记 托管 在 承销团 成员 设置 的 营业网点 认购 的 债券 由 中央 国债 登记 公司 登记 托管'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_sent = cn_text_process(doc_text[3] )\n",
    "new_text_sent.split('，')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('  债券 形式 及 托管 方式 实名制 记账式 债券 投资者 通过 协议 方式 认购 在 上海证券交易所 发行 的 债券 由 中国 证券 登记 公司 上海 分公司 登记 托管 在 承销团 成员 设置 的 营业网点 认购 的 债券 由 中央 国债 登记 公司 登记 托管', [])\n"
     ]
    }
   ],
   "source": [
    "correct_sent = pycorrector.correct(new_text_sent.split('，')[2])\n",
    "print(correct_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
